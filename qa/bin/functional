#!/usr/bin/env python3
# encoding: utf-8
"""
cache.py

Created by Thomas Mangin
Copyright (c) 2013-2017 Exa Networks. All rights reserved.
License: 3-clause BSD. (See the COPYRIGHT file)
"""

import argparse
import glob
import json
import os
import re
import signal
import subprocess
import sys
import time
from enum import Enum
from typing import Any, Dict, Generator, List, Optional, Type

INTERPRETER = os.environ.get('INTERPRETER', '')
if not INTERPRETER:
    INTERPRETER = os.environ.get('__PYVENV_LAUNCHER__', sys.executable)


class Alarm(Exception):
    pass


def flush(*args: Any, **kwars: Any) -> None:
    print(*args, **kwars)
    sys.stdout.flush()


def check_ulimit(minimum: int = 40000) -> None:
    """
    Check and set file descriptor limit (ulimit -n) to at least the minimum value.

    Ensure sufficient file descriptors for tests that spawn many processes.
    Required for functional tests that spawn many simultaneous processes.
    Default minimum is 40000 (encoding tests spawn 72 daemon + 72 client processes).
    """
    try:
        import resource

        # Get current soft and hard limits
        soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)

        # If current limit is sufficient, report and return
        if soft >= minimum:
            flush(f'[ulimit] File descriptor limit is {soft} (sufficient, minimum: {minimum})')
            flush()  # Empty line before starting processes
            return

        # Try to set to minimum (but not higher than hard limit)
        new_limit = min(minimum, hard)

        try:
            resource.setrlimit(resource.RLIMIT_NOFILE, (new_limit, hard))
            flush(f'[ulimit] Increased file descriptor limit from {soft} to {new_limit}')
            flush()  # Empty line before starting processes
        except (ValueError, OSError) as exc:
            # If we can't set it, warn but continue
            flush(f'[ulimit] Warning: Could not increase file descriptor limit from {soft} to {minimum}')
            flush(f'[ulimit] Current limit: {soft}, minimum recommended: {minimum}')
            flush(f'[ulimit] Error: {exc}')
            flush(f'[ulimit] Tests may timeout or fail. Run: ulimit -n {minimum}')

    except ImportError:
        # resource module not available (shouldn't happen on POSIX systems)
        flush('[ulimit] Warning: Could not check file descriptor limit (resource module unavailable)')


def alarm_handler(number: int, frame: Any) -> None:  # pylint: disable=W0613
    raise Alarm()


def color(prefix: int, suffix: int) -> str:
    def code(value: int) -> str:
        return f'\033[{value}m'

    return code(prefix) + code(suffix)


# Color helper functions
def reset() -> str:
    return color(0, 0)  # NORMAL/RESET


def black() -> str:
    return color(0, 30)  # BLACK


def gray() -> str:
    return color(1, 30)  # GRAY (bold black)


def dark_gray() -> str:
    return color(0, 90)  # DARK GRAY


def red() -> str:
    return color(0, 31)  # RED


def bright_red() -> str:
    return color(0, 91)  # BRIGHT RED


def green() -> str:
    return color(0, 32)  # GREEN


def bright_green() -> str:
    return color(1, 92)  # BRIGHT GREEN (bold)


def yellow() -> str:
    return color(0, 33)  # YELLOW


def bright_yellow() -> str:
    return color(0, 93)  # BRIGHT YELLOW


def cyan() -> str:
    return color(0, 36)  # CYAN


class Port:
    base: int = 1790

    @classmethod
    def get(cls) -> int:
        current = cls.base
        cls.base += 1
        return current


class Path:
    PROGRAM = os.path.realpath(__file__)
    ROOT = os.path.abspath(os.path.join(os.path.dirname(PROGRAM), os.path.join('..', '..')))
    SRC = os.path.join(ROOT, 'src')

    ETC = os.path.join(ROOT, 'etc', 'exabgp')
    EXABGP = os.path.join(ROOT, 'sbin', 'exabgp')
    BGP = os.path.join(ROOT, 'qa', 'sbin', 'bgp')
    DECODING = os.path.join(os.path.join(ROOT, 'qa', 'decoding'))
    ENCODING = os.path.join(os.path.join(ROOT, 'qa', 'encoding'))

    ALL_ETC = glob.glob(os.path.join(ETC, '*.conf'))
    ALL_ETC.sort()
    ALL_DECODING = glob.glob(os.path.join(DECODING, '*'))
    ALL_DECODING.sort()
    ALL_ENCODING = glob.glob(os.path.join(ENCODING, '*.ci'))
    ALL_ENCODING.sort()

    @staticmethod
    def etc(fname: str) -> str:
        return os.path.abspath(os.path.join(Path.ETC, fname))

    @staticmethod
    def ci(fname: str, ext: str) -> str:
        return os.path.abspath(os.path.join(Path.ENCODING, fname) + '.' + ext)

    @classmethod
    def validate(cls) -> None:
        if not os.path.isdir(cls.ETC):
            sys.exit('could not find etc folder')

        if not os.path.isdir(cls.ENCODING):
            sys.exit('could not find tests in the qa/encoding folder')

        if not os.path.isdir(cls.DECODING):
            sys.exit('could not find the tests in qa/decoding')

        if not os.path.isfile(cls.EXABGP):
            sys.exit('could not find exabgp')

        if not os.path.isfile(cls.BGP):
            sys.exit('could not find the sequence daemon')


class Exec(object):
    def __init__(self) -> None:
        self.code: int = -1
        self.stdout: bytes = b''
        self.stderr: bytes = b''
        self.message: str = ''
        self._process: Optional[subprocess.Popen] = None
        self.command: str = ''

    def run(self, command: List[str], env: Optional[Dict[str, str]] = None) -> 'Exec':
        self.command = ' '.join([_ if ' ' not in _ else f"'{_}'" for _ in command])
        # Set up environment to disable ExaBGP logging
        if env is None:
            env = os.environ.copy()
            env['exabgp_log_enable'] = 'false'

        # Use PIPE to capture all output for test verification
        self._process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            close_fds=True,
            stdin=subprocess.DEVNULL,
            env=env,
            start_new_session=True,  # Detach from controlling terminal
        )
        return self

    def ready(self) -> bool:
        signal.signal(signal.SIGALRM, alarm_handler)
        try:
            signal.alarm(1)
            polled = self._process.poll()  # type: ignore
            signal.alarm(0)
        except Alarm:
            return False
        except (OSError, ValueError):
            return True
        if polled is None:
            return False
        return True

    def report(self, reason: str = 'issue with exabgp') -> None:
        # Suppress all diagnostic output to keep test results clean
        # flush(reason)
        # flush(f'command> {self.command}')
        # flush(f'return: {self.code}')
        # flush(f'stdout: {self.stdout.decode()}')
        # flush(f'stderr: {self.stderr.decode()}')
        # flush(f'message: {self.message}')
        pass

    def collect(self) -> None:
        if self.stdout:
            return
        if self.stderr:
            return
        if self.code != -1:
            return

        signal.signal(signal.SIGALRM, alarm_handler)
        try:
            signal.alarm(15)
            self.stdout, self.stderr = self._process.communicate()  # type: ignore
            self.code = self._process.returncode  # type: ignore
            signal.alarm(0)
        except ValueError as exc:  # I/O operation on closed file
            self.message = str(exc)
            pass
        except Alarm as exc:
            self.message = str(exc)
            pass

    def terminate(self, collect: bool = True) -> None:
        if self._process is None:
            return
        try:
            self._process.send_signal(signal.SIGTERM)
        except (OSError, ProcessLookupError):  # No such process, Errno 3
            pass
        if collect:
            self.collect()
        # After collect, try to kill any remaining child processes in the process group
        try:
            os.killpg(os.getpgid(self._process.pid), signal.SIGKILL)
        except (OSError, ProcessLookupError, AttributeError):
            pass

    def __del__(self) -> None:
        if self._process is not None:
            self.terminate()


State = Enum('State', 'NONE STARTING RUNNING FAIL SUCCESS SKIP TIMEOUT')


class Record:
    _index: int = 0
    _listing: str = (
        '0123456789' + 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' + 'abcdefghijklmnopqrstuvwxyz' + 'αβγδεζηθικλμνξοπρςστυφχψω'
    )

    def __init__(self, nick: str, name: str) -> None:
        self.nick: str = nick
        self.name: str = name
        self.conf: Dict[str, Any] = dict()
        self.files: List[str] = []
        self.state: Any = State.SKIP
        self.start_time: Optional[float] = None
        self.timeout: float = 999999.0  # Effectively disable per-test timeout, use global timeout only

    @classmethod
    def new(cls, name: str) -> 'Record':
        return cls(cls.next_nick(), name)

    @classmethod
    def next_nick(cls) -> str:
        nick = cls._listing[cls._index]
        cls._index += 1
        return nick

    def skip(self) -> 'Record':
        self.state = State.SKIP
        return self

    def fail(self) -> 'Record':
        self.state = State.FAIL
        return self

    def activate(self) -> 'Record':
        self.state = State.NONE
        return self

    def is_active(self) -> bool:
        return self.state not in (State.SKIP, State.FAIL, State.SUCCESS, State.TIMEOUT)

    def setup(self) -> None:
        if self.state == State.NONE:
            self.state = State.STARTING
            return
        if self.state == State.STARTING:
            self.state = State.RUNNING
            self.start_time = time.time()
            return

    def running(self) -> None:
        self.state = State.RUNNING
        if self.start_time is None:
            self.start_time = time.time()

    def has_timed_out(self) -> bool:
        """Check if test has exceeded its individual timeout"""
        if self.start_time is None:
            return False
        return (time.time() - self.start_time) > self.timeout

    def mark_timeout(self) -> 'Record':
        """Mark test as timed out"""
        self.state = State.TIMEOUT
        return self

    def result(self, success: bool) -> bool:
        if success:
            self.state = State.SUCCESS
        else:
            self.state = State.FAIL
        return success


class Tests:
    def __init__(self, klass: Type[Record]) -> None:
        self.klass: Type[Record] = klass
        self._by_nick: Dict[str, Record] = {}
        self._ordered: List[str] = []
        self._nl: int = 3
        self._start_time: Optional[float] = None
        self._max_timeout: int = 0
        self._daemons_count: int = 0
        self._clients_count: int = 0

    def new(self, name: str) -> Record:
        test = self.klass.new(name)
        self._by_nick[test.nick] = test
        self._ordered.append(test.nick)
        self._ordered.sort()
        return test

    def enable_by_nick(self, nick: str) -> bool:
        if nick in self._by_nick:
            self._by_nick[nick].activate()
            return True
        return False

    def enable_all(self) -> None:
        for nick in self._by_nick:
            self._by_nick[nick].activate()

    def get_by_nick(self, nick: str) -> Record:
        return self._by_nick[nick]

    def registered(self) -> List[Record]:
        return [self._by_nick[nick] for nick in self._ordered]

    def selected(self) -> List[Record]:
        return [self._by_nick[nick] for nick in self._ordered if self._by_nick[nick].is_active()]

    def _iterate(self) -> Generator[List[Record], None, None]:
        number = len(self._ordered)
        lines = number // self._nl

        for line in range(0, lines + 1):
            tests = []
            start = line * self._nl
            for n in range(start, start + self._nl):
                if n >= number:
                    continue
                nick = self._ordered[n]
                tests.append(self._by_nick[nick])
            yield tests

    def listing(self) -> None:
        flush()
        flush('The available tests are:')
        flush()
        for tests in self._iterate():
            parts = []
            for test in tests:
                parts.append(f' {test.nick:2} {test.name:25}')
            flush(''.join(parts))
        flush()

    def short_list(self) -> None:
        flush(' '.join([test.nick for test in self.registered()]))

    def display(
        self,
        daemons_started: Optional[int] = None,
        clients_started: Optional[int] = None,
    ) -> None:
        # Show timer in setup phase with [0/max] format
        if daemons_started is not None and clients_started is not None:
            if self._max_timeout:
                timer = f'{yellow()}timeout{reset()} [{0:2d}/{yellow()}{self._max_timeout:2d}{reset()}]'
            else:
                timer = ''
            status = (
                f'{timer} {cyan()}daemons{reset()} {daemons_started:2d} {cyan()}clients{reset()} {clients_started:2d}'
                if timer
                else f'{cyan()}daemons{reset()} {daemons_started:2d} {cyan()}clients{reset()} {clients_started:2d}'
            )
            # Clear line before writing to prevent artifacts
            flush(f'\r\033[K{status}', end='')
            return

        # Count test states
        remaining = 0
        passed = 0
        failed = 0
        failed_tests = []
        remaining_tests = []

        for test in self.registered():
            if test.state == State.SUCCESS:
                passed += 1
            elif test.state == State.FAIL:
                failed += 1
                failed_tests.append(test.nick)
            elif test.state == State.TIMEOUT:
                failed += 1
                failed_tests.append(test.nick)
            elif test.state in (State.NONE, State.STARTING, State.RUNNING):
                remaining += 1
                remaining_tests.append(test.nick)

        # Show timer: timeout [elapsed/max] - yellow label and max number
        if self._start_time and self._max_timeout:
            elapsed = int(time.time() - self._start_time)
            # Cap elapsed time to max timeout to prevent timer overshoot
            elapsed = min(elapsed, self._max_timeout)
            timer = f'{yellow()}timeout{reset()} [{elapsed:2d}/{yellow()}{self._max_timeout:2d}{reset()}]'
        else:
            timer = ''

        # Prepend daemon/client counts if they're set (for encoding tests) - cyan labels only
        daemon_client = ''
        if self._daemons_count > 0 or self._clients_count > 0:
            daemon_client = (
                f'{cyan()}daemons{reset()} {self._daemons_count:2d} {cyan()}clients{reset()} {self._clients_count:2d}'
            )

        # Format with labels and colors
        # Order: timer, daemon/client, passed, failed (if > 0), remaining
        passed_text = f'{green()}passed{reset()} {passed:2d}'

        # Build status line
        status_parts = [timer, daemon_client, passed_text]

        # Add failed section if there are failures
        # "failed   " (9 chars) only for single test to match "remaining", otherwise "failed" (6 chars)
        if failed > 0:
            label = 'failed   ' if len(self.selected()) == 1 else 'failed'
            failed_text = f'{red()}{label}{reset()} {failed:2d}'
            if failed_tests:
                failed_text += f' [{", ".join(failed_tests)}]'
            status_parts.append(failed_text)

        # Add remaining last, show test IDs if < 10
        remaining_text = f'remaining {remaining:2d}'
        if remaining > 0 and remaining < 10 and remaining_tests:
            remaining_text += f' [{", ".join(remaining_tests)}]'
        status_parts.append(remaining_text)

        status = ' '.join(status_parts)

        # Clear entire line first, then write status, then return to start
        # This prevents "X] X] X]" artifacts when status text gets shorter
        flush(f'\r\033[K{status}', end='')

    def legend(self) -> None:
        flush(
            '\nFormat: timeout [0/max] daemons N clients N -> timeout [elapsed/max] daemons N clients N remaining N passed N failed N [failed test IDs]\n'
        )

    def _print_debug_output(
        self,
        server: Optional['Exec'],
        client: Optional['Exec'],
        num_tests_selected: Optional[int],
    ) -> None:
        """Print detailed server/client output for single test debugging"""
        if (not server and not client) or num_tests_selected != 1:
            return

        flush()
        flush('=' * 60)
        flush('DEBUG OUTPUT (Single Test Mode)')
        flush('=' * 60)

        if server:
            flush()
            flush('SERVER OUTPUT:')
            flush('-' * 60)
            flush(f'Command: {server.command}')
            flush(f'Return code: {server.code}')
            flush('STDOUT:')
            if server.stdout:
                flush(server.stdout.decode('utf-8', errors='replace'))
            else:
                flush('(empty)')
            flush('STDERR:')
            if server.stderr:
                flush(server.stderr.decode('utf-8', errors='replace'))
            else:
                flush('(empty)')
            if server.message:
                flush(f'Message: {server.message}')

        if client:
            flush()
            flush('CLIENT OUTPUT:')
            flush('-' * 60)
            flush(f'Command: {client.command}')
            flush(f'Return code: {client.code}')
            flush('STDOUT:')
            if client.stdout:
                flush(client.stdout.decode('utf-8', errors='replace'))
            else:
                flush('(empty)')
            flush('STDERR:')
            if client.stderr:
                flush(client.stderr.decode('utf-8', errors='replace'))
            else:
                flush('(empty)')
            if client.message:
                flush(f'Message: {client.message}')

    def _print_summary_results(
        self,
        passed: List[str],
        failed: List[str],
        timed_out: List[str],
        skipped: List[str],
    ) -> None:
        """Print test result summary"""
        flush()
        flush('=' * 60)
        flush('TEST SUMMARY')
        flush('=' * 60)

        # Always show all possible outcomes with colors matching the display
        # Only show test IDs for failed and timed out
        # Use fixed-width labels (9 chars) to align numbers
        if passed:
            flush(f'{green()}passed   {reset()} {len(passed):2d}')
        else:
            flush(f'{green()}passed   {reset()} {0:2d}')

        if failed:
            flush(f'{red()}failed   {reset()} {len(failed):2d} [{", ".join(failed)}]')
        else:
            flush(f'failed    {0:2d}')

        if timed_out:
            flush(f'{yellow()}timed out{reset()} {len(timed_out):2d} [{", ".join(timed_out)}]')
        else:
            flush(f'timed out {0:2d}')

        if skipped:
            flush(f'{dark_gray()}skipped  {reset()} {len(skipped):2d}')
        else:
            flush(f'skipped   {0:2d}')

        flush('=' * 60)

        total_run = len(passed) + len(failed) + len(timed_out)
        if total_run > 0:
            success_rate = (len(passed) / total_run) * 100 if total_run > 0 else 0
            flush(f'Total: {total_run} test(s) run, {success_rate:.1f}% passed')

        flush()

    def summary(
        self,
        server: Optional['Exec'] = None,
        client: Optional['Exec'] = None,
        num_tests_selected: Optional[int] = None,
    ) -> None:
        """Print summary of test results

        Args:
            server: Optional server Exec object for single test debugging
            client: Optional client Exec object for single test debugging
            num_tests_selected: Number of tests that were selected to run (before completion)
        """
        # Collect test results into categorized lists
        passed: List[str] = []
        failed: List[str] = []
        timed_out: List[str] = []
        skipped: List[str] = []

        for test in self.registered():
            if test.state == State.SUCCESS:
                passed.append(test.nick)
            elif test.state == State.FAIL:
                failed.append(test.nick)
            elif test.state == State.TIMEOUT:
                timed_out.append(test.nick)
            elif test.state == State.SKIP:
                skipped.append(test.nick)

        # Print debug output if in single test mode
        self._print_debug_output(server, client, num_tests_selected)

        # Print summary results
        self._print_summary_results(passed, failed, timed_out, skipped)


def parse_msg_options(msg_file: str) -> int:
    """Parse option directives from .msg file

    Returns:
        TCP connections count from file, or 1 as default
    """
    try:
        with open(msg_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line.startswith('option:tcp_connections:'):
                    return int(line.split(':')[-1])
    except Exception:
        pass
    return 1


class EncodingTests(Tests):
    class Test(Record, Exec):
        def __init__(self, nick: str, name: str) -> None:
            Record.__init__(self, nick, name)
            Exec.__init__(self)
            self._check: bytes = b'successful'

        # def __eq__ (self, other):
        #     return self.nick.__eq__(other.nick)

        # def __lt__ (self, other):
        #     return self.nick.__lt__(other.nick)

        # def __hash__ (self):
        #     return self.nick.__hash__()

        def success(self) -> bool:
            self.collect()
            if self.code == 0:
                if self._check in self.stdout:
                    if os.getenv('DEBUG', None) is not None:
                        self.report('completed successfully')
                    return True
                if self._check in self.stderr:
                    if os.getenv('DEBUG', None) is not None:
                        self.report('completed successfully')
                    return True

            self.report(f'failed with code {self.code}')
            return False

    API: Any = re.compile(r'^\s*run\s+(.*)\s*?;\s*?$')

    def __init__(self) -> None:
        super().__init__(self.Test)

        for filename in Path.ALL_ENCODING:
            name = os.path.basename(filename)[:-3]
            test = self.new(name)
            with open(filename, 'r') as reader:
                content = reader.readline()
            test.conf['confs'] = [Path.etc(_) for _ in content.split()]
            test.conf['ci'] = Path.ci(name, 'ci')
            test.conf['msg'] = Path.ci(name, 'msg')
            test.conf['port'] = Port.get()
            test.files.extend(test.conf['confs'])
            test.files.append(test.conf['ci'])
            test.files.append(test.conf['msg'])

            for f in test.conf['confs']:
                with open(f) as reader:
                    for line in reader:
                        found = self.API.match(line)
                        if not found:
                            continue
                        name = found.group(1)
                        if not name.startswith('/'):
                            name = Path.etc(name)
                        if name not in test.files:
                            test.files.append(name)

    def client(self, nick: str) -> str:
        if not self.enable_by_nick(nick):
            sys.exit('no such test')
        test = self.get_by_nick(nick)

        # Parse tcp_connections option from .msg file (defaults to 1)
        tcp_connections = parse_msg_options(test.conf['msg'])

        config = {
            'env': ' \\\n  '.join(
                [
                    'exabgp_version=5.0.0-0+test',
                    f'exabgp_tcp_connections={tcp_connections}',
                    'exabgp_api_cli=false',
                    'exabgp_debug_rotate=true',
                    'exabgp_debug_configuration=true',
                    "exabgp_tcp_bind=''",
                    'exabgp_tcp_port=%d' % test.conf['port'],
                    'INTERPRETER=%s' % INTERPRETER,
                ]
            ),
            'exabgp': Path.EXABGP,
            'confs': ' \\\n    '.join(test.conf['confs']),
        }
        return 'env \\\n  %(env)s \\\n   %(exabgp)s -d -p \\\n    %(confs)s' % config

    def server(self, nick: str) -> str:
        if not self.enable_by_nick(nick):
            sys.exit('no such test')
        test = self.get_by_nick(nick)

        config = {
            'env': ' \\\n  '.join(
                [
                    'exabgp_tcp_port=%d' % test.conf['port'],
                ]
            ),
            'interpreter': INTERPRETER,
            'bgp': Path.BGP,
            'msg': test.conf['msg'],
        }

        return 'env \\\n  %(env)s \\\n  %(interpreter)s %(bgp)s --view \\\n    %(msg)s' % config

    def dry(self) -> str:
        result: List[str] = []
        for test in self.selected():
            result.append(
                ' '.join(
                    [
                        '>',
                        sys.argv[0],
                        'encoding',
                        '--server',
                        test.nick,
                        '--port',
                        f'{test.conf["port"]}',
                    ]
                )
            )
            result.append(
                ' '.join(
                    [
                        '>',
                        sys.argv[0],
                        'encoding',
                        '--client',
                        test.nick,
                        '--port',
                        f'{test.conf["port"]}',
                    ]
                )
            )
        return '\n'.join(result)

    def run_selected(self, timeout: int) -> bool:
        # Set max timeout before setup so it shows during initialization
        self._max_timeout = timeout
        self.legend()
        # Ensure sufficient file descriptors for tests that spawn many processes
        check_ulimit()
        success = True
        client = dict()

        # Remember how many tests we're running for single-test debug mode
        num_tests_selected = len(self.selected())

        # Start daemons (servers) - timer shows [0/max] during setup
        daemons_started = 0
        last_daemon_display = -1  # Track last displayed count to avoid duplicates
        for test in self.selected():
            test.setup()
            test.run(
                [
                    sys.argv[0],
                    'encoding',
                    '--server',
                    test.nick,
                    '--port',
                    f'{test.conf["port"]}',
                ]
            )
            daemons_started += 1
            # Only display every 10th daemon and avoid duplicate displays
            if daemons_started % 10 == 0 and daemons_started != last_daemon_display:
                self.display(daemons_started=daemons_started, clients_started=0)
                last_daemon_display = daemons_started
            time.sleep(0.005)

        # Final display for daemons (only if not already displayed)
        if daemons_started != last_daemon_display:
            self.display(daemons_started=daemons_started, clients_started=0)
        time.sleep(0.02)

        # Start clients - timer shows [0/max] during setup
        clients_started = 0
        last_client_display = -1  # Track last displayed count to avoid duplicates
        for test in self.selected():
            test.setup()
            client[test.nick] = Exec().run(
                [
                    sys.argv[0],
                    'encoding',
                    '--client',
                    test.nick,
                    '--port',
                    f'{test.conf["port"]}',
                ]
            )
            clients_started += 1
            # Only display every 10th client and avoid duplicate displays
            if clients_started % 10 == 0 and clients_started != last_client_display:
                self.display(daemons_started=daemons_started, clients_started=clients_started)
                last_client_display = clients_started
            time.sleep(0.005)

        # Final display for clients (only if not already displayed)
        if clients_started != last_client_display:
            self.display(daemons_started=daemons_started, clients_started=clients_started)

        # Store daemon and client counts for display during test execution
        self._daemons_count = daemons_started
        self._clients_count = clients_started

        # Start timer AFTER setup is complete
        self._start_time = time.time()

        exit_time = time.time() + timeout
        last_display = 0  # Track last display time to throttle updates

        running = set(self.selected())

        while running:
            current_time = time.time()

            # Check timeout first
            if current_time >= exit_time:
                # Show final display before cleanup to avoid timer overshoot
                self.display()
                break

            # Throttle display updates to once per second
            if current_time - last_display >= 1.0:
                self.display()
                last_display = current_time

            for test in list(running):
                # Check per-test timeout first
                if test.has_timed_out():
                    running.remove(test)
                    test.mark_timeout()
                    test.terminate(collect=False)  # Don't block on collect in hot loop
                    client[test.nick].terminate(collect=False)
                    success = False
                    continue

                if not test.ready():
                    continue
                if not client[test.nick].ready():
                    continue
                running.remove(test)
                client[test.nick].terminate(collect=False)  # Don't block on collect in hot loop
                success = test.result(test.success()) and success

            # If no tests are still running, exit immediately
            if not running:
                # Show final display before cleanup
                self.display()
                break

            time.sleep(0.1)

        # Clean up any remaining running tests without blocking
        for test in running:
            test.mark_timeout()
            test.terminate(collect=False)
            client[test.nick].terminate(collect=False)
            success = False

        # Move to new line after final display
        flush()

        # For single test mode, collect output and pass server and client debug info
        server_exec = None
        client_exec = None
        if num_tests_selected == 1:
            # Get all registered tests (including completed ones)
            all_tests = self.registered()
            # Find the one test that was selected (not skipped)
            test = None
            for t in all_tests:
                if t.state != State.SKIP:
                    test = t
                    break

            if test:
                server_exec = test
                client_exec = client.get(test.nick)
                # Ensure output is collected for display
                if client_exec and not client_exec.stdout and not client_exec.stderr:
                    client_exec.collect()

        self.summary(
            server=server_exec,
            client=client_exec,
            num_tests_selected=num_tests_selected,
        )
        return success


class DecodingTests(Tests):
    class Test(Record, Exec):
        def __init__(self, nick, name):
            Record.__init__(self, nick, name)
            Exec.__init__(self)

        def _cleanup(self, decoded):
            decoded.pop('exabgp', None)
            decoded.pop('host', None)
            decoded.pop('pid', None)
            decoded.pop('ppid', None)
            decoded.pop('time', None)
            decoded.pop('version', None)
            return decoded

        def success(self):
            self.collect()
            if self.stderr:
                self.report('stderr is \n' + self.stderr.decode())
                return False
            if not self.stdout:
                self.report('no stdout received')
                return False
            try:
                decoded = json.loads(self.stdout)
                self._cleanup(decoded)
            except Exception:
                self.report('issue, report to decode the JSON')
                return False
            if decoded != self.conf['json']:
                from pprint import pformat

                failure = 'issue, JSON does not match'
                failure += f'\ndecoded : {pformat(decoded)}\n'
                failure += f'\nexpected: {pformat(self.conf["json"])}'
                self.report(failure)
                return False
            return True

    def __init__(self) -> None:
        super().__init__(self.Test)

        for filename in Path.ALL_DECODING:
            name = os.path.basename(filename).split('.')[0]
            test = self.new(name)
            with open(filename, 'r') as reader:
                words = reader.readline().split()
                test.conf['type'] = words[0]
                test.conf['family'] = '' if words[0] == 'open' else f'{words[1]} {words[2]}'
                packet = reader.readline().replace(' ', '').strip()
                test.conf['packet'] = packet
                expected = reader.readline().strip()
                decoded = json.loads(expected)
                test.conf['json'] = test._cleanup(decoded)
            test.files.append(filename)

    def listing(self) -> None:
        flush()
        flush('The available tests are:')
        flush()
        for tests in self._iterate():
            parts = []
            for test in tests:
                parts.append(f' {test.nick:2} {test.name:25}')
            flush(''.join(parts))
        flush()

    def dry(self) -> str:
        result = []
        for test in self.selected():
            result.append(
                ' '.join(
                    [
                        '>',
                        Path.EXABGP,
                        'decode',
                        f"'-f {test.conf['family']}'" if test.conf['family'] else '',
                        '--%s' % test.conf['type'],
                        test.conf['packet'],
                    ]
                )
            )
        return '\n'.join(result)

    def run_selected(self, timeout: int) -> bool:
        self._start_time = time.time()
        self._max_timeout = timeout
        self.legend()
        # Ensure sufficient file descriptors for tests that spawn many processes
        check_ulimit()
        success = True
        for test in self.selected():
            test.running()
            self.display()
            message = test.conf['type']
            if message == 'open':
                cmd = [
                    Path.EXABGP,
                    'decode',
                    '--%s' % test.conf['type'],
                    test.conf['packet'],
                ]
            elif message in ['update', 'nlri']:
                cmd = [
                    Path.EXABGP,
                    'decode',
                    '-f',
                    test.conf['family'],
                    '--%s' % test.conf['type'],
                    test.conf['packet'],
                ]
            else:
                raise ValueError(f'invalid message type: {message}')
            test.run(cmd)

        for test in self.selected():
            self.display()
            success = test.result(test.success()) and success
            time.sleep(0.05)

        exit_time = time.time() + timeout
        last_display = 0  # Track last display time to throttle updates
        running = set(self.selected())

        while running:
            current_time = time.time()

            # Check timeout first
            if current_time >= exit_time:
                # Show final display before cleanup to avoid timer overshoot
                self.display()
                break

            # Throttle display updates to once per second
            if current_time - last_display >= 1.0:
                self.display()
                last_display = current_time

            for test in list(running):
                # Check per-test timeout first
                if test.has_timed_out():
                    running.remove(test)
                    test.mark_timeout()
                    test.terminate(collect=False)  # Don't block on collect in hot loop
                    success = False
                    continue

                if not test.ready():
                    continue
                running.remove(test)
                success = test.result(test.success()) and success

            # If no tests are still running, exit immediately
            if not running:
                # Show final display before cleanup
                self.display()
                break

            time.sleep(0.1)

        # Clean up any remaining running tests without blocking
        for test in running:
            test.mark_timeout()
            test.terminate(collect=False)
            success = False

        # Move to new line after final display
        flush()

        self.summary()
        return success


class ParsingTests(Tests):
    class Test(Record, Exec):
        def __init__(self, nick, name):
            Record.__init__(self, nick, name)
            Exec.__init__(self)

        def success(self):
            self.collect()
            if self.code != 0:
                self.report('return code is not zero')
                return False

            return self.code == 0

    def __init__(self) -> None:
        super().__init__(self.Test)

        for filename in Path.ALL_ETC:
            name = os.path.basename(filename).split('.')[0]
            test = self.new(name)
            test.conf['fname'] = filename
            test.files.append(filename)

    def listing(self) -> None:
        flush()
        flush('The available tests are:')
        flush()
        for tests in self._iterate():
            parts = []
            for test in tests:
                parts.append(f' {test.nick:2} {test.name:25}')
            flush(''.join(parts))
        flush()

    def dry(self) -> str:
        result = []
        for test in self.selected():
            result.append(' '.join(['>', Path.EXABGP, 'validate', '-nrv', test.conf['fname']]))
        return '\n'.join(result)

    def run_selected(self, timeout: int) -> bool:
        self._start_time = time.time()
        self._max_timeout = timeout
        self.legend()
        # Ensure sufficient file descriptors for tests that spawn many processes
        check_ulimit()
        success = True

        for test in self.selected():
            test.running()
            test.run([Path.EXABGP, 'validate', '-nrv', test.conf['fname']])
            time.sleep(0.005)

        time.sleep(0.02)

        for test in self.selected():
            success = test.result(test.success()) and success
            time.sleep(0.005)

        exit_time = time.time() + timeout
        last_display = 0  # Track last display time to throttle updates
        running = set(self.selected())

        while running:
            current_time = time.time()

            # Check timeout first
            if current_time >= exit_time:
                # Show final display before cleanup to avoid timer overshoot
                self.display()
                break

            # Throttle display updates to once per second
            if current_time - last_display >= 1.0:
                self.display()
                last_display = current_time

            for test in list(running):
                # Check per-test timeout first
                if test.has_timed_out():
                    running.remove(test)
                    test.mark_timeout()
                    test.terminate(collect=False)  # Don't block on collect in hot loop
                    success = False
                    continue

                if not test.ready():
                    continue
                running.remove(test)
                success = test.result(test.success()) and success

            # If no tests are still running, exit immediately
            if not running:
                # Show final display before cleanup
                self.display()
                break

            time.sleep(0.1)

        # Clean up any remaining running tests without blocking
        for test in running:
            test.mark_timeout()
            test.terminate(collect=False)
            success = False

        # Move to new line after final display
        flush()

        self.summary()
        return success


def add_test(subparser: Any, name: str, tests: Tests, extra: List[str]) -> None:
    sub = subparser.add_parser(name, help=f'run {name} test')
    if 'dry' in extra:
        sub.add_argument('--dry', help='show the action', action='store_true')
    if 'server' in extra:
        sub.add_argument('--server', help='start the server for a test', type=str, default=None)
    if 'client' in extra:
        sub.add_argument('--client', help='start the client for a test', type=str, default=None)
    if 'list' in extra:
        sub.add_argument('--list', help='list the files making a test', action='store_true')
    if 'short_list' in extra:
        sub.add_argument(
            '--short-list',
            help='list test codes only (space separated)',
            action='store_true',
        )
    if 'edit' in extra:
        sub.add_argument('--edit', help='edit the files making a test', action='store_true')
    if 'timeout' in extra:
        sub.add_argument(
            '--timeout',
            help='total timeout for all tests (seconds)',
            type=int,
            default=20,
        )
    if 'port' in extra:
        sub.add_argument('--port', help='base port to use', type=int, default=1790)
    sub.add_argument('test', help='name of the test(s) to run', nargs='*', default=None)

    def func(parsed: Any) -> None:
        if 'edit' in extra and parsed.edit:
            if not parsed.test or len(parsed.test) != 1:
                sys.exit('--edit requires exactly one test')
            if not tests.enable_by_nick(parsed.test[0]):
                sys.exit('no such test')
            test = tests.get_by_nick(parsed.test[0])
            if not test.files:
                sys.exit('no file for the test')
            editor = os.environ.get('EDITOR', 'vi')
            command = '%s %s' % (editor, ' '.join(test.files))
            flush(f'> {command}')
            if not parsed.dry:
                sys.exit(os.system(command))
            return

        if 'list' in extra and parsed.list:
            tests.listing()
            return

        if 'short_list' in extra and parsed.short_list:
            tests.short_list()
            return

        if 'client' in extra and parsed.client:
            command = tests.client(parsed.client)
            flush(f'client> {command}')
            if not parsed.dry:
                sys.exit(os.system(command))
            return

        if 'server' in extra and parsed.server:
            command = tests.server(parsed.server)
            flush(f'server> {command}')
            if not parsed.dry:
                sys.exit(os.system(command))
            return

        if 'timeout' not in parsed:
            parsed.timeout = 0

        if parsed.test:
            # Enable multiple tests if provided
            for test_nick in parsed.test:
                if not tests.enable_by_nick(test_nick):
                    sys.exit(f'could not find test {test_nick}')
        else:
            tests.enable_all()

        if parsed.dry:
            command = tests.dry()
            flush(command)
            sys.exit(0)

        exit = tests.run_selected(parsed.timeout)
        flush()
        sys.exit(0 if exit else 1)

    sub.set_defaults(func=func)


if __name__ == '__main__':
    Path.validate()

    decoding = DecodingTests()
    encoding = EncodingTests()
    parsing = ParsingTests()

    parser = argparse.ArgumentParser(description='The BGP swiss army knife of networking functional testing tool')
    subparser = parser.add_subparsers()

    add_test(
        subparser,
        'decoding',
        decoding,
        ['list', 'short_list', 'edit', 'dry', 'timeout', 'port'],
    )
    add_test(
        subparser,
        'encoding',
        encoding,
        ['list', 'short_list', 'edit', 'dry', 'timeout', 'port', 'server', 'client'],
    )
    add_test(subparser, 'parsing', parsing, ['list', 'short_list', 'dry', 'edit'])

    parsed = parser.parse_args()
    if vars(parsed):
        parsed.func(parsed)
    else:
        parser.print_help()
