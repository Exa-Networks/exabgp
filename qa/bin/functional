#!/usr/bin/env python3
# encoding: utf-8
"""
cache.py

Created by Thomas Mangin
Copyright (c) 2013-2017 Exa Networks. All rights reserved.
License: 3-clause BSD. (See the COPYRIGHT file)
"""

import os
import re
import sys
import json
import glob
import time
import signal
import argparse
import subprocess
from enum import Enum


INTERPRETER = os.environ.get('INTERPRETER', '')
if not INTERPRETER:
    INTERPRETER = os.environ.get('__PYVENV_LAUNCHER__', sys.executable)


class Alarm(Exception):
    pass


def flush(*args, **kwars):
    print(*args, **kwars)
    sys.stdout.flush()


def check_ulimit(minimum=40000):
    """
    Check and set file descriptor limit (ulimit -n) to at least the minimum value.

    Ensure sufficient file descriptors for tests that spawn many processes.
    Required for functional tests that spawn many simultaneous processes.
    Default minimum is 40000 (encoding tests spawn 72 daemon + 72 client processes).
    """
    try:
        import resource

        # Get current soft and hard limits
        soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)

        # If current limit is sufficient, report and return
        if soft >= minimum:
            flush(f'[ulimit] File descriptor limit is {soft} (sufficient, minimum: {minimum})')
            flush()  # Empty line before starting processes
            return

        # Try to set to minimum (but not higher than hard limit)
        new_limit = min(minimum, hard)

        try:
            resource.setrlimit(resource.RLIMIT_NOFILE, (new_limit, hard))
            flush(f'[ulimit] Increased file descriptor limit from {soft} to {new_limit}')
            flush()  # Empty line before starting processes
        except (ValueError, OSError) as exc:
            # If we can't set it, warn but continue
            flush(f'[ulimit] Warning: Could not increase file descriptor limit from {soft} to {minimum}')
            flush(f'[ulimit] Current limit: {soft}, minimum recommended: {minimum}')
            flush(f'[ulimit] Error: {exc}')
            flush(f'[ulimit] Tests may timeout or fail. Run: ulimit -n {minimum}')

    except ImportError:
        # resource module not available (shouldn't happen on POSIX systems)
        flush('[ulimit] Warning: Could not check file descriptor limit (resource module unavailable)')


def alarm_handler(number, frame):  # pylint: disable=W0613
    raise Alarm()


def color(prefix, suffix):
    def code(value):
        return f'\033[{value}m'

    return code(prefix) + code(suffix)


class Port:
    base = 1790

    @classmethod
    def get(cls):
        current = cls.base
        cls.base += 1
        return current


class Path:
    PROGRAM = os.path.realpath(__file__)
    ROOT = os.path.abspath(os.path.join(os.path.dirname(PROGRAM), os.path.join('..', '..')))
    SRC = os.path.join(ROOT, 'src')

    ETC = os.path.join(ROOT, 'etc', 'exabgp')
    EXABGP = os.path.join(ROOT, 'sbin', 'exabgp')
    BGP = os.path.join(ROOT, 'qa', 'sbin', 'bgp')
    DECODING = os.path.join(os.path.join(ROOT, 'qa', 'decoding'))
    ENCODING = os.path.join(os.path.join(ROOT, 'qa', 'encoding'))

    ALL_ETC = glob.glob(os.path.join(ETC, '*.conf'))
    ALL_ETC.sort()
    ALL_DECODING = glob.glob(os.path.join(DECODING, '*'))
    ALL_DECODING.sort()
    ALL_ENCODING = glob.glob(os.path.join(ENCODING, '*.ci'))
    ALL_ENCODING.sort()

    @staticmethod
    def etc(fname):
        return os.path.abspath(os.path.join(Path.ETC, fname))

    @staticmethod
    def ci(fname, ext):
        return os.path.abspath(os.path.join(Path.ENCODING, fname) + '.' + ext)

    @classmethod
    def validate(cls):
        if not os.path.isdir(cls.ETC):
            sys.exit('could not find etc folder')

        if not os.path.isdir(cls.ENCODING):
            sys.exit('could not find tests in the qa/encoding folder')

        if not os.path.isdir(cls.DECODING):
            sys.exit('could not find the tests in qa/decoding')

        if not os.path.isfile(cls.EXABGP):
            sys.exit('could not find exabgp')

        if not os.path.isfile(cls.BGP):
            sys.exit('could not find the sequence daemon')


class Exec(object):
    def __init__(self):
        self.code = -1
        self.stdout = b''
        self.stderr = b''
        self.message = ''
        self._process = None
        self.command = []

    def run(self, command, env=None):
        self.command = ' '.join([_ if ' ' not in _ else f"'{_}'" for _ in command])
        # Set up environment to disable ExaBGP logging
        if env is None:
            env = os.environ.copy()
            env['exabgp_log_enable'] = 'false'

        # Use PIPE to capture all output for test verification
        self._process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            close_fds=True,
            stdin=subprocess.DEVNULL,
            env=env,
            start_new_session=True,  # Detach from controlling terminal
        )
        return self

    def ready(self):
        signal.signal(signal.SIGALRM, alarm_handler)
        try:
            signal.alarm(1)
            polled = self._process.poll()
            signal.alarm(0)
        except Alarm:
            return False
        except (OSError, ValueError):
            return True
        if polled is None:
            return False
        return True

    def report(self, reason='issue with exabgp'):
        # Suppress all diagnostic output to keep test results clean
        # flush(reason)
        # flush(f'command> {self.command}')
        # flush(f'return: {self.code}')
        # flush(f'stdout: {self.stdout.decode()}')
        # flush(f'stderr: {self.stderr.decode()}')
        # flush(f'message: {self.message}')
        pass

    def collect(self):
        if self.stdout:
            return
        if self.stderr:
            return
        if self.code != -1:
            return

        signal.signal(signal.SIGALRM, alarm_handler)
        try:
            signal.alarm(15)
            self.stdout, self.stderr = self._process.communicate()
            self.code = self._process.returncode
            signal.alarm(0)
        except ValueError as exc:  # I/O operation on closed file
            self.message = str(exc)
            pass
        except Alarm as exc:
            self.message = str(exc)
            pass

    def terminate(self, collect=True):
        if self._process is None:
            return
        try:
            self._process.send_signal(signal.SIGTERM)
        except (OSError, ProcessLookupError):  # No such process, Errno 3
            pass
        if collect:
            self.collect()
        # After collect, try to kill any remaining child processes in the process group
        try:
            os.killpg(os.getpgid(self._process.pid), signal.SIGKILL)
        except (OSError, ProcessLookupError, AttributeError):
            pass

    def __del__(self):
        if self._process is not None:
            self.terminate()


State = Enum('State', 'NONE STARTING RUNNING FAIL SUCCESS SKIP TIMEOUT')


class Record:
    _index = 0
    _listing = '0123456789' + 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' + 'abcdefghijklmnopqrstuvwxyz' + 'αβγδεζηθικλμνξοπρςστυφχψω'

    def __init__(self, nick, name):
        self.nick = nick
        self.name = name
        self.conf = dict()
        self.files = []
        self.state = State.SKIP
        self.start_time = None
        self.timeout = 999999.0  # Effectively disable per-test timeout, use global timeout only

    @classmethod
    def new(cls, name):
        return cls(cls.next_nick(), name)

    @classmethod
    def next_nick(cls):
        nick = cls._listing[cls._index]
        cls._index += 1
        return nick

    def skip(self):
        self.state = State.SKIP
        return self

    def fail(self):
        self.state = State.FAIL
        return self

    def activate(self):
        self.state = State.NONE
        return self

    def is_active(self):
        return self.state not in (State.SKIP, State.FAIL, State.SUCCESS, State.TIMEOUT)

    def setup(self):
        if self.state == State.NONE:
            self.state = State.STARTING
            return
        if self.state == State.STARTING:
            self.state = State.RUNNING
            self.start_time = time.time()
            return

    def running(self):
        self.state = State.RUNNING
        if self.start_time is None:
            self.start_time = time.time()

    def has_timed_out(self):
        """Check if test has exceeded its individual timeout"""
        if self.start_time is None:
            return False
        return (time.time() - self.start_time) > self.timeout

    def mark_timeout(self):
        """Mark test as timed out"""
        self.state = State.TIMEOUT
        return self

    def colored(self):
        if self.state == State.NONE:
            return color(0, 30) + self.nick  # BLACK
        if self.state == State.STARTING:
            return color(1, 30) + self.nick  # GRAY
        if self.state == State.RUNNING:
            return color(0, 0) + self.nick  # NORMAL
        if self.state == State.FAIL:
            return color(0, 91) + '✖'  # RED - Failed test
        if self.state == State.SUCCESS:
            return color(1, 92) + '✓'  # GREEN - Successful test
        if self.state == State.SKIP:
            return color(0, 90) + '○'  # GRAY - Skipped test
        if self.state == State.TIMEOUT:
            return color(0, 93) + '⏱'  # YELLOW - Timed out test

    def result(self, success):
        if success:
            self.state = State.SUCCESS
        else:
            self.state = State.FAIL
        return success


class Tests:
    def __init__(self, klass):
        self.klass = klass
        self._by_nick = {}
        self._ordered = []
        self._nl = 3
        self._start_time = None
        self._max_timeout = 0
        self._daemons_count = 0
        self._clients_count = 0

    def new(self, name):
        test = self.klass.new(name)
        self._by_nick[test.nick] = test
        self._ordered.append(test.nick)
        self._ordered.sort()
        return test

    def enable_by_nick(self, nick):
        if nick in self._by_nick:
            self._by_nick[nick].activate()
            return True
        return False

    def enable_all(self):
        for nick in self._by_nick:
            self._by_nick[nick].activate()

    def get_by_nick(self, nick):
        return self._by_nick[nick]

    def registered(self):
        return [self._by_nick[nick] for nick in self._ordered]

    def selected(self):
        return [self._by_nick[nick] for nick in self._ordered if self._by_nick[nick].is_active()]

    def _iterate(self):
        number = len(self._ordered)
        lines = number // self._nl

        for line in range(0, lines + 1):
            tests = []
            start = line * self._nl
            for n in range(start, start + self._nl):
                if n >= number:
                    continue
                nick = self._ordered[n]
                tests.append(self._by_nick[nick])
            yield tests

    def listing(self):
        flush()
        flush('The available tests are:')
        flush()
        for tests in self._iterate():
            parts = []
            for test in tests:
                parts.append(f' {test.nick:2} {test.name:25}')
            flush(''.join(parts))
        flush()

    def short_list(self):
        flush(' '.join([test.nick for test in self.registered()]))

    def display(self, daemons_started=None, clients_started=None):
        # Show timer in setup phase with [0/max] format
        if daemons_started is not None and clients_started is not None:
            if self._max_timeout:
                timer = (
                    f'{color(0, 33)}timeout{color(0, 0)} [{0:2d}/{color(0, 33)}{self._max_timeout:2d}{color(0, 0)}]'
                )
            else:
                timer = ''
            status = f'{timer} {color(0, 36)}daemons{color(0, 0)} {daemons_started:2d} {color(0, 36)}clients{color(0, 0)} {clients_started:2d}' if timer else f'{color(0, 36)}daemons{color(0, 0)} {daemons_started:2d} {color(0, 36)}clients{color(0, 0)} {clients_started:2d}'
            # Clear line before writing to prevent artifacts
            flush(f'\r\033[K{status}', end='')
            return

        # Count test states
        remaining = 0
        passed = 0
        failed = 0
        failed_tests = []
        remaining_tests = []

        for test in self.registered():
            if test.state == State.SUCCESS:
                passed += 1
            elif test.state == State.FAIL:
                failed += 1
                failed_tests.append(test.nick)
            elif test.state == State.TIMEOUT:
                failed += 1
                failed_tests.append(test.nick)
            elif test.state in (State.NONE, State.STARTING, State.RUNNING):
                remaining += 1
                remaining_tests.append(test.nick)

        # Show timer: timeout [elapsed/max] - yellow label and max number
        if self._start_time and self._max_timeout:
            elapsed = int(time.time() - self._start_time)
            # Cap elapsed time to max timeout to prevent timer overshoot
            elapsed = min(elapsed, self._max_timeout)
            timer = (
                f'{color(0, 33)}timeout{color(0, 0)} [{elapsed:2d}/{color(0, 33)}{self._max_timeout:2d}{color(0, 0)}]'
            )
        else:
            timer = ''

        # Prepend daemon/client counts if they're set (for encoding tests) - cyan labels only
        daemon_client = ''
        if self._daemons_count > 0 or self._clients_count > 0:
            daemon_client = f'{color(0, 36)}daemons{color(0, 0)} {self._daemons_count:2d} {color(0, 36)}clients{color(0, 0)} {self._clients_count:2d}'

        # Format with labels and colors
        # Order: timer, daemon/client, passed, failed (if > 0), remaining
        passed_text = f'{color(0, 32)}passed{color(0, 0)} {passed:2d}'

        # Build status line
        status_parts = [timer, daemon_client, passed_text]

        # Add failed section if there are failures
        # "failed   " (9 chars) only for single test to match "remaining", otherwise "failed" (6 chars)
        if failed > 0:
            label = 'failed   ' if len(self.selected()) == 1 else 'failed'
            failed_text = f'{color(0, 31)}{label}{color(0, 0)} {failed:2d}'
            if failed_tests:
                failed_text += f' [{", ".join(failed_tests)}]'
            status_parts.append(failed_text)

        # Add remaining last, show test IDs if < 10
        remaining_text = f'remaining {remaining:2d}'
        if remaining > 0 and remaining < 10 and remaining_tests:
            remaining_text += f' [{", ".join(remaining_tests)}]'
        status_parts.append(remaining_text)

        status = ' '.join(status_parts)

        # Clear entire line first, then write status, then return to start
        # This prevents "X] X] X]" artifacts when status text gets shorter
        flush(f'\r\033[K{status}', end='')

    def legend(self):
        flush('\nFormat: timeout [0/max] daemons N clients N -> timeout [elapsed/max] daemons N clients N remaining N passed N failed N [failed test IDs]\n')

    def summary(self):
        """Print summary of test results"""
        passed = []
        failed = []
        timed_out = []
        skipped = []

        for test in self.registered():
            if test.state == State.SUCCESS:
                passed.append(test.nick)
            elif test.state == State.FAIL:
                failed.append(test.nick)
            elif test.state == State.TIMEOUT:
                timed_out.append(test.nick)
            elif test.state == State.SKIP:
                skipped.append(test.nick)

        flush()
        flush('=' * 60)
        flush('TEST SUMMARY')
        flush('=' * 60)

        # Always show all possible outcomes with colors matching the display
        # Only show test IDs for failed and timed out
        # Use fixed-width labels (9 chars) to align numbers
        if passed:
            flush(f'{color(0, 32)}passed   {color(0, 0)} {len(passed):2d}')
        else:
            flush(f'{color(0, 32)}passed   {color(0, 0)} {0:2d}')

        if failed:
            flush(f'{color(0, 31)}failed   {color(0, 0)} {len(failed):2d} [{", ".join(failed)}]')
        else:
            flush(f'failed    {0:2d}')

        if timed_out:
            flush(f'{color(0, 33)}timed out{color(0, 0)} {len(timed_out):2d} [{", ".join(timed_out)}]')
        else:
            flush(f'timed out {0:2d}')

        if skipped:
            flush(f'{color(0, 90)}skipped  {color(0, 0)} {len(skipped):2d}')
        else:
            flush(f'skipped   {0:2d}')

        flush('=' * 60)

        total_run = len(passed) + len(failed) + len(timed_out)
        if total_run > 0:
            success_rate = (len(passed) / total_run) * 100 if total_run > 0 else 0
            flush(f'Total: {total_run} test(s) run, {success_rate:.1f}% passed')

        flush()


def parse_msg_options(msg_file):
    """Parse option directives from .msg file"""
    tcp_connections = None
    try:
        with open(msg_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line.startswith('option:tcp_connections:'):
                    tcp_connections = int(line.split(':')[-1])
                    break
    except Exception:
        pass
    return tcp_connections


class EncodingTests(Tests):
    class Test(Record, Exec):
        def __init__(self, nick, name):
            Record.__init__(self, nick, name)
            Exec.__init__(self)
            self._check = b'successful'

        # def __eq__ (self, other):
        #     return self.nick.__eq__(other.nick)

        # def __lt__ (self, other):
        #     return self.nick.__lt__(other.nick)

        # def __hash__ (self):
        #     return self.nick.__hash__()

        def success(self):
            self.collect()
            if self.code == 0:
                if self._check in self.stdout:
                    if os.getenv('DEBUG', None) is not None:
                        self.report('completed successfully')
                    return True
                if self._check in self.stderr:
                    if os.getenv('DEBUG', None) is not None:
                        self.report('completed successfully')
                    return True

            self.report(f'failed with code {self.code}')
            return False

    API = re.compile(r'^\s*run\s+(.*)\s*?;\s*?$')

    def __init__(self):
        super().__init__(self.Test)

        for filename in Path.ALL_ENCODING:
            name = os.path.basename(filename)[:-3]
            test = self.new(name)
            with open(filename, 'r') as reader:
                content = reader.readline()
            test.conf['confs'] = [Path.etc(_) for _ in content.split()]
            test.conf['ci'] = Path.ci(name, 'ci')
            test.conf['msg'] = Path.ci(name, 'msg')
            test.conf['port'] = Port.get()
            test.files.extend(test.conf['confs'])
            test.files.append(test.conf['ci'])
            test.files.append(test.conf['msg'])

            for f in test.conf['confs']:
                with open(f) as reader:
                    for line in reader:
                        found = self.API.match(line)
                        if not found:
                            continue
                        name = found.group(1)
                        if not name.startswith('/'):
                            name = Path.etc(name)
                        if name not in test.files:
                            test.files.append(name)

    def explain(self, nick):
        template = '\n'
        template += 'exabgp\n'
        template += '-' * 55 + '\n\n'
        template += '%(client)s\n\n\n'
        template += 'bgp deamon\n'
        template += '-' * 55 + '\n\n'
        template += '%(server)s\n\n\n'
        template += 'The following extra configuration options could be used\n'
        template += '-' * 55 + '\n\n'
        template += 'export exabgp_debug_rotate=true\n'
        template += 'export exabgp_debug_defensive=true\n'

        flush(
            template
            % {
                'client': self.client(nick),
                'server': self.server(nick),
            }
        )

    def client(self, nick):
        if not self.enable_by_nick(nick):
            sys.exit('no such test')
        test = self.get_by_nick(nick)

        # Parse tcp_connections option from .msg file, default to 1 if not specified
        tcp_connections = parse_msg_options(test.conf['msg']) or 1

        config = {
            'env': ' \\\n  '.join(
                [
                    'exabgp_version=5.0.0-0+test',
                    f'exabgp_tcp_connections={tcp_connections}',
                    'exabgp_api_cli=false',
                    'exabgp_debug_rotate=true',
                    'exabgp_debug_configuration=true',
                    "exabgp_tcp_bind=''",
                    'exabgp_tcp_port=%d' % test.conf['port'],
                    'INTERPRETER=%s' % INTERPRETER,
                ]
            ),
            'exabgp': Path.EXABGP,
            'confs': ' \\\n    '.join(test.conf['confs']),
        }
        return 'env \\\n  %(env)s \\\n   %(exabgp)s -d -p \\\n    %(confs)s' % config

    def server(self, nick):
        if not self.enable_by_nick(nick):
            sys.exit('no such test')
        test = self.get_by_nick(nick)

        config = {
            'env': ' \\\n  '.join(
                [
                    'exabgp_tcp_port=%d' % test.conf['port'],
                ]
            ),
            'interpreter': INTERPRETER,
            'bgp': Path.BGP,
            'msg': test.conf['msg'],
        }

        return 'env \\\n  %(env)s \\\n  %(interpreter)s %(bgp)s --view \\\n    %(msg)s' % config

    def dry(self):
        result = []
        for test in self.selected():
            result.append(
                ' '.join(
                    [
                        '>',
                        sys.argv[0],
                        'encoding',
                        '--server',
                        test.nick,
                        '--port',
                        f'{test.conf["port"]}',
                    ]
                )
            )
            result.append(
                ' '.join(
                    [
                        '>',
                        sys.argv[0],
                        'encoding',
                        '--client',
                        test.nick,
                        '--port',
                        f'{test.conf["port"]}',
                    ]
                )
            )
        return '\n'.join(result)

    def run_selected(self, timeout):
        # Set max timeout before setup so it shows during initialization
        self._max_timeout = timeout
        self.legend()
        # Ensure sufficient file descriptors for tests that spawn many processes
        check_ulimit()
        success = True
        client = dict()

        # Start daemons (servers) - timer shows [0/max] during setup
        daemons_started = 0
        last_daemon_display = -1  # Track last displayed count to avoid duplicates
        for test in self.selected():
            test.setup()
            test.run(
                [
                    sys.argv[0],
                    'encoding',
                    '--server',
                    test.nick,
                    '--port',
                    f'{test.conf["port"]}',
                ]
            )
            daemons_started += 1
            # Only display every 10th daemon and avoid duplicate displays
            if daemons_started % 10 == 0 and daemons_started != last_daemon_display:
                self.display(daemons_started=daemons_started, clients_started=0)
                last_daemon_display = daemons_started
            time.sleep(0.005)

        # Final display for daemons (only if not already displayed)
        if daemons_started != last_daemon_display:
            self.display(daemons_started=daemons_started, clients_started=0)
        time.sleep(0.02)

        # Start clients - timer shows [0/max] during setup
        clients_started = 0
        last_client_display = -1  # Track last displayed count to avoid duplicates
        for test in self.selected():
            test.setup()
            client[test.nick] = Exec().run(
                [
                    sys.argv[0],
                    'encoding',
                    '--client',
                    test.nick,
                    '--port',
                    f'{test.conf["port"]}',
                ]
            )
            clients_started += 1
            # Only display every 10th client and avoid duplicate displays
            if clients_started % 10 == 0 and clients_started != last_client_display:
                self.display(daemons_started=daemons_started, clients_started=clients_started)
                last_client_display = clients_started
            time.sleep(0.005)

        # Final display for clients (only if not already displayed)
        if clients_started != last_client_display:
            self.display(daemons_started=daemons_started, clients_started=clients_started)

        # Store daemon and client counts for display during test execution
        self._daemons_count = daemons_started
        self._clients_count = clients_started

        # Start timer AFTER setup is complete
        self._start_time = time.time()

        exit_time = time.time() + timeout
        last_display = 0  # Track last display time to throttle updates

        running = set(self.selected())

        while running:
            current_time = time.time()

            # Check timeout first
            if current_time >= exit_time:
                # Show final display before cleanup to avoid timer overshoot
                self.display()
                break

            # Throttle display updates to once per second
            if current_time - last_display >= 1.0:
                self.display()
                last_display = current_time

            for test in list(running):
                # Check per-test timeout first
                if test.has_timed_out():
                    running.remove(test)
                    test.mark_timeout()
                    test.terminate(collect=False)  # Don't block on collect in hot loop
                    client[test.nick].terminate(collect=False)
                    success = False
                    continue

                if not test.ready():
                    continue
                if not client[test.nick].ready():
                    continue
                running.remove(test)
                client[test.nick].terminate(collect=False)  # Don't block on collect in hot loop
                success = test.result(test.success()) and success

            # If no tests are still running, exit immediately
            if not running:
                # Show final display before cleanup
                self.display()
                break

            time.sleep(0.1)

        # Clean up any remaining running tests without blocking
        for test in running:
            test.mark_timeout()
            test.terminate(collect=False)
            client[test.nick].terminate(collect=False)
            success = False

        # Move to new line after final display
        flush()

        self.summary()
        return success


class DecodingTests(Tests):
    class Test(Record, Exec):
        def __init__(self, nick, name):
            Record.__init__(self, nick, name)
            Exec.__init__(self)

        def _cleanup(self, decoded):
            decoded.pop('exabgp', None)
            decoded.pop('host', None)
            decoded.pop('pid', None)
            decoded.pop('ppid', None)
            decoded.pop('time', None)
            decoded.pop('version', None)
            return decoded

        def success(self):
            self.collect()
            if self.stderr:
                self.report('stderr is \n' + self.stderr.decode())
                return False
            if not self.stdout:
                self.report('no stdout received')
                return False
            try:
                decoded = json.loads(self.stdout)
                self._cleanup(decoded)
            except Exception:
                self.report('issue, report to decode the JSON')
                return False
            if decoded != self.conf['json']:
                from pprint import pformat

                failure = 'issue, JSON does not match'
                failure += f'\ndecoded : {pformat(decoded)}\n'
                failure += f'\nexpected: {pformat(self.conf["json"])}'
                self.report(failure)
                return False
            return True

    def __init__(self):
        super().__init__(self.Test)

        for filename in Path.ALL_DECODING:
            name = os.path.basename(filename).split('.')[0]
            test = self.new(name)
            with open(filename, 'r') as reader:
                words = reader.readline().split()
                test.conf['type'] = words[0]
                test.conf['family'] = '' if words[0] == 'open' else f'{words[1]} {words[2]}'
                packet = reader.readline().replace(' ', '').strip()
                test.conf['packet'] = packet
                expected = reader.readline().strip()
                decoded = json.loads(expected)
                test.conf['json'] = test._cleanup(decoded)
            test.files.append(filename)

    def listing(self):
        flush()
        flush('The available tests are:')
        flush()
        for tests in self._iterate():
            parts = []
            for test in tests:
                parts.append(f' {test.nick:2} {test.name:25}')
            flush(''.join(parts))
        flush()

    def dry(self):
        result = []
        for test in self.selected():
            result.append(
                ' '.join(
                    [
                        '>',
                        Path.EXABGP,
                        'decode',
                        f"'-f {test.conf['family']}'" if test.conf['family'] else '',
                        '--%s' % test.conf['type'],
                        test.conf['packet'],
                    ]
                )
            )
        return '\n'.join(result)

    def run_selected(self, timeout):
        self._start_time = time.time()
        self._max_timeout = timeout
        self.legend()
        # Ensure sufficient file descriptors for tests that spawn many processes
        check_ulimit()
        success = True
        for test in self.selected():
            test.running()
            self.display()
            message = test.conf['type']
            if message == 'open':
                cmd = [
                    Path.EXABGP,
                    'decode',
                    '--%s' % test.conf['type'],
                    test.conf['packet'],
                ]
            elif message in ['update', 'nlri']:
                cmd = [
                    Path.EXABGP,
                    'decode',
                    '-f',
                    test.conf['family'],
                    '--%s' % test.conf['type'],
                    test.conf['packet'],
                ]
            else:
                raise ValueError(f'invalid message type: {message}')
            test.run(cmd)

        for test in self.selected():
            self.display()
            success = test.result(test.success()) and success
            time.sleep(0.05)

        exit_time = time.time() + timeout
        last_display = 0  # Track last display time to throttle updates
        running = set(self.selected())

        while running:
            current_time = time.time()

            # Check timeout first
            if current_time >= exit_time:
                # Show final display before cleanup to avoid timer overshoot
                self.display()
                break

            # Throttle display updates to once per second
            if current_time - last_display >= 1.0:
                self.display()
                last_display = current_time

            for test in list(running):
                # Check per-test timeout first
                if test.has_timed_out():
                    running.remove(test)
                    test.mark_timeout()
                    test.terminate(collect=False)  # Don't block on collect in hot loop
                    success = False
                    continue

                if not test.ready():
                    continue
                running.remove(test)
                success = test.result(test.success()) and success

            # If no tests are still running, exit immediately
            if not running:
                # Show final display before cleanup
                self.display()
                break

            time.sleep(0.1)

        # Clean up any remaining running tests without blocking
        for test in running:
            test.mark_timeout()
            test.terminate(collect=False)
            success = False

        # Move to new line after final display
        flush()

        self.summary()
        return success


class ParsingTests(Tests):
    class Test(Record, Exec):
        def __init__(self, nick, name):
            Record.__init__(self, nick, name)
            Exec.__init__(self)

        def success(self):
            self.collect()
            if self.code != 0:
                self.report('return code is not zero')
                return False

            return self.code == 0

    def __init__(self):
        super().__init__(self.Test)

        for filename in Path.ALL_ETC:
            name = os.path.basename(filename).split('.')[0]
            test = self.new(name)
            test.conf['fname'] = filename
            test.files.append(filename)

    def listing(self):
        flush()
        flush('The available tests are:')
        flush()
        for tests in self._iterate():
            parts = []
            for test in tests:
                parts.append(f' {test.nick:2} {test.name:25}')
            flush(''.join(parts))
        flush()

    def dry(self):
        result = []
        for test in self.selected():
            result.append(' '.join(['>', Path.EXABGP, 'validate', '-nrv', test.conf['fname']]))
        return '\n'.join(result)

    def run_selected(self, timeout):
        self._start_time = time.time()
        self._max_timeout = timeout
        self.legend()
        # Ensure sufficient file descriptors for tests that spawn many processes
        check_ulimit()
        success = True

        for test in self.selected():
            test.running()
            test.run([Path.EXABGP, 'validate', '-nrv', test.conf['fname']])
            time.sleep(0.005)

        time.sleep(0.02)

        for test in self.selected():
            success = test.result(test.success()) and success
            time.sleep(0.005)

        exit_time = time.time() + timeout
        last_display = 0  # Track last display time to throttle updates
        running = set(self.selected())

        while running:
            current_time = time.time()

            # Check timeout first
            if current_time >= exit_time:
                # Show final display before cleanup to avoid timer overshoot
                self.display()
                break

            # Throttle display updates to once per second
            if current_time - last_display >= 1.0:
                self.display()
                last_display = current_time

            for test in list(running):
                # Check per-test timeout first
                if test.has_timed_out():
                    running.remove(test)
                    test.mark_timeout()
                    test.terminate(collect=False)  # Don't block on collect in hot loop
                    success = False
                    continue

                if not test.ready():
                    continue
                running.remove(test)
                success = test.result(test.success()) and success

            # If no tests are still running, exit immediately
            if not running:
                # Show final display before cleanup
                self.display()
                break

            time.sleep(0.1)

        # Clean up any remaining running tests without blocking
        for test in running:
            test.mark_timeout()
            test.terminate(collect=False)
            success = False

        # Move to new line after final display
        flush()

        self.summary()
        return success


def add_test(subparser, name, tests, extra):
    sub = subparser.add_parser(name, help=f'run {name} test')
    if 'dry' in extra:
        sub.add_argument('--dry', help='show the action', action='store_true')
    if 'server' in extra:
        sub.add_argument('--server', help='start the server for a test', type=str, default=None)
    if 'client' in extra:
        sub.add_argument('--client', help='start the client for a test', type=str, default=None)
    if 'list' in extra:
        sub.add_argument('--list', help='list the files making a test', action='store_true')
    if 'short_list' in extra:
        sub.add_argument('--short-list', help='list test codes only (space separated)', action='store_true')
    if 'edit' in extra:
        sub.add_argument('--edit', help='edit the files making a test', action='store_true')
    if 'timeout' in extra:
        sub.add_argument('--timeout', help='total timeout for all tests (seconds)', type=int, default=20)
    if 'port' in extra:
        sub.add_argument('--port', help='base port to use', type=int, default=1790)
    sub.add_argument('test', help='name of the test(s) to run', nargs='*', default=None)

    def func(parsed):
        if 'edit' in extra and parsed.edit:
            if not parsed.test or len(parsed.test) != 1:
                sys.exit('--edit requires exactly one test')
            if not tests.enable_by_nick(parsed.test[0]):
                sys.exit('no such test')
            test = tests.get_by_nick(parsed.test[0])
            if not test.files:
                sys.exit('no file for the test')
            editor = os.environ.get('EDITOR', 'vi')
            command = '%s %s' % (editor, ' '.join(test.files))
            flush(f'> {command}')
            if not parsed.dry:
                sys.exit(os.system(command))
            return

        if 'list' in extra and parsed.list:
            tests.listing()
            return

        if 'short_list' in extra and parsed.short_list:
            tests.short_list()
            return

        if 'client' in extra and parsed.client:
            command = tests.client(parsed.client)
            flush(f'client> {command}')
            if not parsed.dry:
                sys.exit(os.system(command))
            return

        if 'server' in extra and parsed.server:
            command = tests.server(parsed.server)
            flush(f'server> {command}')
            if not parsed.dry:
                sys.exit(os.system(command))
            return

        if 'timeout' not in parsed:
            parsed.timeout = 0

        if parsed.test:
            # Enable multiple tests if provided
            for test_nick in parsed.test:
                if not tests.enable_by_nick(test_nick):
                    sys.exit(f'could not find test {test_nick}')
        else:
            tests.enable_all()

        if parsed.dry:
            command = tests.dry()
            flush(command)
            sys.exit(0)

        exit = tests.run_selected(parsed.timeout)
        flush()
        sys.exit(0 if exit else 1)

    sub.set_defaults(func=func)


if __name__ == '__main__':
    Path.validate()

    decoding = DecodingTests()
    encoding = EncodingTests()
    parsing = ParsingTests()

    parser = argparse.ArgumentParser(description='The BGP swiss army knife of networking functional testing tool')
    subparser = parser.add_subparsers()

    add_test(subparser, 'decoding', decoding, ['list', 'short_list', 'edit', 'dry', 'timeout', 'port'])
    add_test(
        subparser,
        'encoding',
        encoding,
        ['list', 'short_list', 'edit', 'dry', 'timeout', 'port', 'server', 'client'],
    )
    add_test(subparser, 'parsing', parsing, ['list', 'short_list', 'dry', 'edit'])

    parsed = parser.parse_args()
    if vars(parsed):
        parsed.func(parsed)
    else:
        parser.print_help()
